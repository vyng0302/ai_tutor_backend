{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b48efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import packages\n",
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the API key\n",
    "openai.api_key = os.environ.get('API_KEY')\n",
    "\n",
    "#Load Data\n",
    "def load_data(ss_questions_filepath, faqs_filepath):\n",
    "    ss_questions_data = pd.read_excel(ss_questions_filepath)\n",
    "    faqs_data = pd.read_excel(faqs_filepath)\n",
    "    default_question = ss_questions_data['question'].iloc[0]\n",
    "    return ss_questions_data, faqs_data, default_question\n",
    "\n",
    "# Load the data\n",
    "ss_questions_filepath = 'final_updated_cleaned_SS_questions.xlsx'\n",
    "faqs_filepath = 'ai_tutor_faqs.xlsx'\n",
    "ss_questions_data, faqs_data, default_question = load_data(ss_questions_filepath, faqs_filepath)\n",
    "\n",
    "#Define Helper Functions\n",
    "class QueryHandler:\n",
    "    \n",
    "    def __init__(self, ss_questions_data, faqs_data):\n",
    "        self.ss_questions_data = ss_questions_data\n",
    "        self.faqs_data = faqs_data\n",
    "\n",
    "    # Get FAQ response\n",
    "    def get_faq_response(self, query):\n",
    "        if query in self.faqs_data['FAQs'].values:\n",
    "            return self.faqs_data[self.faqs_data['FAQs'] == query]['Answer'].iloc[0]\n",
    "        else:\n",
    "            return \"Sorry, I couldn't find the requested information in the FAQs.\"\n",
    "    \n",
    "    # GPT live\n",
    "    def get_completion_from_chat(self, messages):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            presence_penalty=1,\n",
    "            frequency_penalty=1,\n",
    "            max_tokens=3000\n",
    "        )\n",
    "        return response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "    # Handle general questions\n",
    "    def handle_general_query(self, query, request_type=None, further_clarification=False):\n",
    "        system_message = \"You are a programming assistant specialized in Python and data science. You should only answer questions related to these topics.\"\n",
    "        if request_type == \"Get Walkthrough\":\n",
    "            user_message = f\"Provide a general walkthrough for the query: {query}\"\n",
    "        elif request_type == \"Explain Solution\":\n",
    "            user_message = f\"Explain the solution for the query: {query}\"\n",
    "        elif request_type == \"Get Hint\":\n",
    "            user_message = f\"Provide a hint for solving the query: {query}\"\n",
    "        else:\n",
    "            user_message = f\"Can you provide general information about the following topic: {query}\"\n",
    "        \n",
    "        if further_clarification:\n",
    "            user_message += \"Please provide detailed steps and examples.\"\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "        \n",
    "        response = self.get_completion_from_chat(messages)\n",
    "        \n",
    "        if \"I can't assist with that request\" in response or \"I can't provide information on that topic\" in response:\n",
    "            return \"The question doesn't seem to be related to Python or Data Science. Please provide a more specific question or choose from the provided options.\"\n",
    "        \n",
    "        return response\n",
    "\n",
    "    # Get default answers from the database\n",
    "    def get_initial_response(self, query, request_type):\n",
    "        question_data = self.ss_questions_data[self.ss_questions_data['question'] == query].iloc[0].to_dict()\n",
    "        if request_type == \"Get Walkthrough\":\n",
    "            return question_data.get('python_hint', 'No walkthrough available.')\n",
    "        elif request_type == \"Get Solution\":\n",
    "            return question_data.get('python_solution', 'No explanation available.')\n",
    "        elif request_type == \"Get Hint\":\n",
    "            return question_data.get('hint', 'No hint available.')\n",
    "        else:\n",
    "            return \"Unknown request.\"\n",
    "    \n",
    "    # Respond to the query\n",
    "    def respond_to_query(self, input_text, dropdown_selection, request_type, further_clarification, *args):\n",
    "        query = input_text if input_text and input_text != \"Type your question or select from the dropdown.\" else dropdown_selection\n",
    "        query = query or default_question\n",
    "\n",
    "        if query in self.faqs_data['FAQs'].values:\n",
    "            return self.get_faq_response(query)\n",
    "\n",
    "        elif query in self.ss_questions_data['question'].values:\n",
    "            if not further_clarification:\n",
    "                return self.get_initial_response(query, request_type)\n",
    "            else:\n",
    "                system_message = \"You are a helpful assistant.\"\n",
    "                user_message = f\"Please elaborate on the solution for the following problem. Provide steps of instructions and include an example of code in each step:{query}\"\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": system_message},\n",
    "                    {\"role\": \"user\", \"content\": user_message}\n",
    "                ]\n",
    "                return self.get_completion_from_chat(messages)\n",
    "        else:\n",
    "            return self.handle_general_query(query)\n",
    "\n",
    "        \n",
    "\n",
    "#Main Function and Interface\n",
    "query_handler = QueryHandler(ss_questions_data, faqs_data)\n",
    "app_launch = gr.Interface(\n",
    "    fn=query_handler.respond_to_query,\n",
    "    inputs=[\n",
    "        gr.Textbox(default=\"Type your question or select from the dropdown.\", type=\"text\", label=\"Your Question\"),\n",
    "        gr.Dropdown(choices=faqs_data['FAQs'].tolist(), label=\"Or Select a FAQ Question\"),\n",
    "        gr.Radio(choices=[\"Get Walkthrough\", \"Get Solution\", \"Get Hint\"], label=\"Request Type\"),\n",
    "        gr.Checkbox(label=\"Seek further clarification?\", default=False)\n",
    "    ],\n",
    "    outputs=gr.Textbox(default=\"Chatbot is typing...\", type=\"text\", label=\"Output\"),\n",
    "    description=f\"## Question: {default_question}\",\n",
    "    live=False,\n",
    "    flagging=False,\n",
    "    theme=\"dark\",\n",
    "    allow_flagging=False,\n",
    "    title=\"AI Tutor\"\n",
    ")\n",
    "\n",
    "app_launch.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581d31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd435bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f8cd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54622c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7c561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a3745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34707604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
